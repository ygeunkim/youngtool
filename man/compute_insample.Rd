% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assessment.R
\name{compute_insample}
\alias{compute_insample}
\title{In-Sample Error}
\usage{
compute_insample(
  data,
  ny,
  fit,
  rand,
  error = c("squared", "absolute"),
  mod,
  formula,
  ...
)
}
\arguments{
\item{data}{MC data set generated by \code{\link{mc_data}}.}

\item{ny}{the number of response at each x point}

\item{fit}{True model function with \code{x}-named argument.}

\item{rand}{Random sample generator function for error term. By default, \link[stats]{rnorm}}

\item{error}{Choice of loss function. See \code{\link{loss}}.}

\item{mod}{Model function.}

\item{formula}{an object of class \link[stats]{formula}.}

\item{...}{Additional arguments for \code{mod}. If you wand argument for \code{rand}, define one.}
}
\value{
Training error, Insample error, Optimism
}
\description{
This function computes training error, in-sample error, and optimism in MC simulation setting.
}
\details{
In-sample error differs from Expected test error in that it is computed in the same predictor values.
Instead, it uses new response values at each predictor point.
\deqn{Err_{in} = \frac{1}{N} \sum_{i = 1}^N E_{y_0} [L(Y_i^{(0)}, \hat{f}(x_i)) \mid T]}
Optimism is the difference between the insample error and the training error.
}
\references{
Hastie, T., Tibshirani, R.,, Friedman, J. (2001). \emph{The Elements of Statistical Learning}. New York, NY, USA: Springer New York Inc..
}
