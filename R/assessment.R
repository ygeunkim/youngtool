#' Loss operation
#'
#' @description
#' Binary operation method for character
#' @param lhs numeric or character
#' @param rhs numeric or character
#' @return
#' For numeric, compute division. Otherwise, misclassification.
#' @details
#' This function can deal with both regression and classification problem.
#' @export
`%m%` <- function(lhs, rhs) {
  if (is.numeric(lhs) & is.numeric(rhs)) {
    lhs - rhs
  } else {
    lhs == rhs
  }
}

#' In-Sample Error
#'
#' @description
#' This function computes training error, in-sample error, and optimism in MC simulation setting.
#' @param data MC data set generated by \code{\link{mc_data}}.
#' @param ny the number of response at each x point
#' @param fit True model function with \code{x}-named argument.
#' @param rand Random sample generator function for error term. By default, \link[stats]{rnorm}
#' @param mod Model function.
#' @param formula an object of class \link[stats]{formula}.
#' @param ... Additional arguments for \code{mod}. If you wand argument for \code{rand}, define one.
#' @return
#' Training error, Insample error, Optimism
#' @details
#' In-sample error differs from Expected test error in that it is computed in the same predictor values.
#' Instead, it uses new response values at each predictor point.
#' \deqn{Err_{in} = \frac{1}{N} \sum_{i = 1}^N E_{y_0} [L(Y_i^{(0)}, \hat{f}(x_i)) \mid T]}
#' Optimism is the difference between the insample error and the training error.
#' @references Hastie, T., Tibshirani, R.,, Friedman, J. (2001). \emph{The Elements of Statistical Learning}. New York, NY, USA: Springer New York Inc..
#' @import data.table
#' @export
compute_insample <- function(data, ny, fit, rand, mod, formula, ...) {
  if (!("y" %in% names(data))) data <- gen_y(data, fit, rand, fit_col = FALSE)
  cols <- paste0("y", 1:ny)
  for (col in cols) {
    data[,
         (col) := fit(x) + rand(.N)]
  }
  data <- pred_dt(data = data, mod = mod, formula = formula, ...)
  data %>%
    melt(id.vars = c("x", "y", "mc", "pred")) %>%
    .[,
      .(
        training = mean((y %m% pred)^2),
        insample = mean((value %m% pred)^2)
      ),
      by = mc] %>%
    .[,
      optimism := insample - training] %>%
    .[,
      lapply(.SD, mean),
      .SDcols = -"mc"]
}
